# ğŸ’° BalanceX - Control de Ingresos y Gastos con IA

Sistema web en React para control de ingresos y gastos personales con **control por voz usando Inteligencia Artificial** (Whisper de OpenAI).

## âœ¨ CaracterÃ­sticas

- ğŸ™ï¸ **Control por voz con IA**: Usa Whisper de OpenAI para transcribir y procesar comandos de voz
- ğŸ’¾ **Backend en Supabase**: Almacenamiento seguro en la nube con autenticaciÃ³n
- ğŸ” **AutenticaciÃ³n OAuth**: Inicia sesiÃ³n con Google o Apple
- ğŸ“Š **Filtros por perÃ­odo**: Visualiza tus movimientos por dÃ­a, mes, mes pasado o aÃ±o
- ğŸ·ï¸ **CategorÃ­as automÃ¡ticas**: El sistema detecta automÃ¡ticamente la categorÃ­a del gasto/ingreso
- ğŸ“± **DiseÃ±o responsive**: Funciona perfectamente en mÃ³vil y desktop
- ğŸ¨ **UI minimalista**: Inspirado en Google Material Design

## ğŸ¤ Ejemplos de comandos de voz

El sistema interpreta automÃ¡ticamente comandos como:

- "GastÃ© 5000 pesos en comida"
- "Me ingresaron 200000 de sueldo"
- "PaguÃ© 3000 de internet"
- "Ingresaron 15000 por un trabajo"
- "ComprÃ© ropa por 12 mil pesos"
- "CobrÃ© 50000 de freelance"

## ğŸš€ ConfiguraciÃ³n

### 1. Instalar dependencias

```bash
npm install
```

### 2. Configurar Supabase

1. Crea una cuenta en [Supabase](https://supabase.com)
2. Crea un nuevo proyecto
3. Ve a **SQL Editor** y ejecuta el script `supabase-schema.sql`
4. Ve a **Settings** > **API** y copia:
   - `Project URL` (SUPABASE_URL)
   - `anon public` key (SUPABASE_ANON_KEY)

### 3. Configurar OpenAI (Whisper)

1. Crea una cuenta en [OpenAI](https://platform.openai.com)
2. Ve a **API Keys** y crea una nueva clave
3. Copia la clave API

### 4. Configurar variables de entorno

Crea un archivo `.env.local` en la raÃ­z del proyecto:

```env
VITE_SUPABASE_URL=https://tu-proyecto.supabase.co
VITE_SUPABASE_ANON_KEY=tu_anon_key_aqui
VITE_OPENAI_API_KEY=sk-tu_openai_api_key_aqui
```

### 5. Configurar OAuth (Google y Apple)

#### Google OAuth

1. Ve a [Google Cloud Console](https://console.cloud.google.com)
2. Crea un nuevo proyecto o selecciona uno existente
3. Habilita **Google+ API**
4. Ve a **Credentials** > **Create Credentials** > **OAuth 2.0 Client ID**
5. Configura las URLs de redirecciÃ³n:
   - `https://tu-proyecto.supabase.co/auth/v1/callback`
6. Copia el **Client ID** y **Client Secret**
7. En Supabase, ve a **Authentication** > **Providers** > **Google**
8. Pega las credenciales y habilita el provider

#### Apple OAuth

1. Ve a [Apple Developer](https://developer.apple.com)
2. Crea un **Service ID** para Sign in with Apple
3. Configura las URLs de redirecciÃ³n:
   - `https://tu-proyecto.supabase.co/auth/v1/callback`
4. En Supabase, ve a **Authentication** > **Providers** > **Apple**
5. Configura las credenciales y habilita el provider

### 6. Ejecutar el proyecto

```bash
npm run dev
```

Abre [http://localhost:5173](http://localhost:5173) en tu navegador.

## ğŸ“ Estructura del proyecto

```
balancex/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useAudioRecorder.js    # Hook para grabar audio
â”‚   â”‚   â””â”€â”€ useTransactions.js     # Hook para manejar transacciones
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ supabase.js            # Cliente de Supabase
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ whisperService.js      # Servicio de Whisper AI
â”‚   â”œâ”€â”€ App.jsx                    # Componente principal
â”‚   â”œâ”€â”€ index.css                  # Estilos globales
â”‚   â””â”€â”€ main.jsx                   # Punto de entrada
â”œâ”€â”€ supabase-schema.sql            # Schema de base de datos
â”œâ”€â”€ .env.local                     # Variables de entorno (no commitear)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ—„ï¸ Schema de base de datos

La tabla `transactions` tiene la siguiente estructura:

| Campo       | Tipo      | DescripciÃ³n                          |
|-------------|-----------|--------------------------------------|
| id          | UUID      | ID Ãºnico de la transacciÃ³n           |
| user_id     | UUID      | ID del usuario (FK a auth.users)     |
| type        | TEXT      | Tipo: 'ingreso' o 'egreso'           |
| amount      | DECIMAL   | Monto de la transacciÃ³n              |
| description | TEXT      | DescripciÃ³n del movimiento           |
| category    | TEXT      | CategorÃ­a (comida, transporte, etc.) |
| created_at  | TIMESTAMP | Fecha de creaciÃ³n                    |
| updated_at  | TIMESTAMP | Fecha de Ãºltima actualizaciÃ³n        |

## ğŸ”’ Seguridad

- **Row Level Security (RLS)**: Los usuarios solo pueden ver sus propias transacciones
- **AutenticaciÃ³n OAuth**: Inicio de sesiÃ³n seguro con Google/Apple
- **API Keys**: Las claves se almacenan en variables de entorno
- **HTTPS**: Todas las comunicaciones estÃ¡n encriptadas

## ğŸ¨ CategorÃ­as disponibles

El sistema detecta automÃ¡ticamente las siguientes categorÃ­as:

- ğŸ” Comida
- ğŸš— Transporte
- ğŸ’¡ Servicios
- ğŸ¥ Salud
- ğŸ¬ Entretenimiento
- ğŸ“š EducaciÃ³n
- ğŸ‘• Ropa
- ğŸ  Hogar
- ğŸ’¼ Sueldo
- ğŸ’» Freelance
- ğŸ“¦ Otro

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **React 18** - Framework frontend
- **Vite** - Build tool
- **Supabase** - Backend as a Service (BaaS)
- **OpenAI Whisper** - TranscripciÃ³n de voz con IA
- **Lucide React** - Iconos
- **MediaRecorder API** - GrabaciÃ³n de audio

## ğŸ“ Notas importantes

### Sobre el uso de Whisper en el navegador

âš ï¸ **IMPORTANTE**: La configuraciÃ³n actual usa `dangerouslyAllowBrowser: true` en el cliente de OpenAI. Esto es **solo para desarrollo**.

Para producciÃ³n, debes:

1. Crear un backend (Node.js, Python, etc.)
2. Mover la lÃ³gica de Whisper al backend
3. Exponer un endpoint API que reciba el audio
4. Llamar a ese endpoint desde el frontend

Ejemplo de endpoint backend (Node.js):

```javascript
// backend/api/transcribe.js
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export async function POST(req) {
  const formData = await req.formData();
  const audioFile = formData.get('audio');
  
  const transcription = await openai.audio.transcriptions.create({
    file: audioFile,
    model: 'whisper-1',
    language: 'es'
  });
  
  return Response.json({ text: transcription });
}
```

### Costos de OpenAI

- Whisper API: $0.006 por minuto de audio
- Ejemplo: 100 comandos de voz de 5 segundos = ~$0.05

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas! Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.

## ğŸ› Reportar problemas

Si encuentras algÃºn bug o tienes una sugerencia, por favor abre un [issue](https://github.com/tu-usuario/balancex/issues).

## ğŸ“§ Contacto

Tu Nombre - [@tu_twitter](https://twitter.com/tu_twitter)

Project Link: [https://github.com/tu-usuario/balancex](https://github.com/tu-usuario/balancex)

---

Hecho con â¤ï¸ usando React, Supabase y OpenAI Whisper
